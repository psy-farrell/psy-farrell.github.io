<p>Some bits of writing a paper can be fun—finding a good way to present an argument, or coming up with a theory that explains some weird results. Other bits are just plain dull, and some of the dullest must be method and results sections. Transcribing F values, p values and degrees of freedom from your stats package into a paper really is not something that researchers should be spending time on. Furthermore, these are the bits that we as psychologists are getting wrong. Some recent and disturbing evidence comes from Bakker &amp; Wicherts (2011), who showed that an alarming number of papers contain errors in their reporting of statistical results (and these errors are biased towards finding a significant result).</p>

<p>One solution is to automate statistical reporting as much as possible, which in turn implies automating the analysis/modelling process itself. Indeed, a recent movement (see, e.g., http://www.sciencemag.org/content/334/6060/1226.full) urges for reproducible research, whereby data are made available to other researchers along with the precise code that was used to turn those data into the results reported in a scientific paper. To link the analyses with what actually appears in a published article, programs such as R have been integrated with LaTeX via such packages as Sweave. I use MATLAB to run many of analyses, and integration with Sweave hasn’t really progressed. Furthermore, I actually call SPSS from MATLAB so I get some of the useful stuff that SPSS prints out (like effect sizes and contrasts), whilst using MATLAB to do the grunt work of scoring up performance. So instead I wrote this addin, which takes Excel output exported from SPSS for a repeated measures ANOVA, and turns it into LaTeX-ready output. It would be straightforward to do the same for between-subjects effects, regression etc.—I just very rarely use these!</p>

<p>Bakker, M. &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666-678.</p>